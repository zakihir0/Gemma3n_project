#%%
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

!pip install pip3-autoremove
!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124
!pip install unsloth
!pip install faiss-cpu
!pip install sentence-transformers
!pip install wikipedia
!pip install --no-deps git+https://github.com/huggingface/transformers.git
!pip install --no-deps --upgrade timm
#%%
import torch
import pandas as pd
import random
import numpy as np
import faiss
import wikipedia
import json
import re
import time
from dataclasses import dataclass
from typing import Optional, List, Dict, Any, Tuple
from unsloth import FastModel
from transformers import TextStreamer
from torchvision import datasets, transforms, models
from sentence_transformers import SentenceTransformer

# Load the model
model, tokenizer = FastModel.from_pretrained(
    model_name = "unsloth/gemma-3n-E2B-it",
    dtype = None,
    max_seq_length = 1024,
    load_in_4bit = True,
    full_finetuning = False,
)

# Helper function for inference
def do_gemma_3n_inference(messages, max_new_tokens = 128):
    inputs = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt = True,
        tokenize = True,
        return_dict = True,
        return_tensors = "pt",
    ).to("cuda")
    
    # å¸¸ã«å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦è¿”ã™
    outputs = model.generate(
        **inputs,
        max_new_tokens = max_new_tokens,
        temperature = 1.0, top_p = 0.95, top_k = 64,
        do_sample = True,
        pad_token_id = tokenizer.eos_token_id,
    )
    # æ–°ã—ãç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æŠ½å‡º
    response_tokens = outputs[0][inputs['input_ids'].shape[1]:]
    response_text = tokenizer.decode(response_tokens, skip_special_tokens=True)
    return response_text

#%%
%%time
dir0='/kaggle/input/mushroom1/merged_dataset'
max_files_per_class = 1000  # Limit files per class to control total dataset size

classes=[]
paths=[]
class_file_counts = {}
for dirname, _, filenames in os.walk(dir0):
    class_name = dirname.split('/')[-1]
    if class_name not in class_file_counts:
        class_file_counts[class_name] = 0
    
    for filename in filenames:
        if class_file_counts[class_name] < max_files_per_class:
            classes+=[class_name]
            paths+=[(os.path.join(dirname, filename))]
            class_file_counts[class_name] += 1

dataset0=datasets.ImageFolder(root=dir0)
class_names=dataset0.classes
print(class_names)
print(len(class_names))

N=list(range(len(classes)))
normal_mapping=dict(zip(class_names,N))
reverse_mapping=dict(zip(N,class_names))

data=pd.DataFrame(columns=['path','class','label'])
data['path']=paths
data['class']=classes
data['label']=data['class'].map(normal_mapping)
print(len(data))

def create_path_label_list(df):
    path_label_list = []
    for _, row in df.iterrows():
        path = row['path']
        label = row['label']
        path_label_list.append((path, label))
    return path_label_list

path_label = create_path_label_list(data)
path_label = random.sample(path_label,20000)
print(len(path_label))
print(path_label[0:3])

image_path, label = path_label[0]

#%%
# RAG (Retrieval-Augmented Generation) Implementation
class WikipediaRAG:
    def __init__(self, embedding_model='all-MiniLM-L6-v2'):
        """
        Initialize RAG system with Wikipedia as knowledge base
        """
        self.embedding_model = SentenceTransformer(embedding_model)
        self.documents = []
        self.embeddings = None
        self.index = None

    def search_wikipedia(self, query: str, num_results: int = 5) -> List[str]:
        """
        Search Wikipedia and return page contents
        """
        try:
            search_results = wikipedia.search(query, results=num_results)
            documents = []
            
            for title in search_results:
                try:
                    page = wikipedia.page(title)
                    # Split content into chunks for better retrieval
                    content = page.content
                    chunks = self._split_text(content, chunk_size=500)
                    for chunk in chunks:
                        if len(chunk.strip()) > 100:  # Filter out very short chunks
                            documents.append({
                                'title': title,
                                'content': chunk,
                                'url': page.url
                            })
                except wikipedia.exceptions.DisambiguationError as e:
                    # Take the first option if disambiguation occurs
                    try:
                        page = wikipedia.page(e.options[0])
                        content = page.content
                        chunks = self._split_text(content, chunk_size=500)
                        for chunk in chunks:
                            if len(chunk.strip()) > 100:
                                documents.append({
                                    'title': e.options[0],
                                    'content': chunk,
                                    'url': page.url
                                })
                    except:
                        continue
                except:
                    continue
                    
            return documents
        except:
            return []
    
    def _split_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """
        Split text into overlapping chunks
        """
        # Clean text
        text = re.sub(r'\s+', ' ', text.strip())
        
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # Try to break at sentence boundaries
            if end < len(text):
                # Look for sentence endings
                sentence_end = text.rfind('.', start, end)
                if sentence_end > start + chunk_size // 2:
                    end = sentence_end + 1
            
            chunks.append(text[start:end].strip())
            start = end - overlap
            
        return chunks

    def search_species_dynamically(self, species_candidates: List, knowledge_base_type: str = "general") -> List[Dict]:
        """æ¨å®šç¨®ã«å¯¾ã™ã‚‹å‹•çš„Wikipediaæ¤œç´¢"""
        
        dynamic_documents = []
        
        for i, candidate in enumerate(species_candidates[:3]):  # ä¸Šä½3å€™è£œã®ã¿
            species_name = candidate.name
            confidence = candidate.score
            
            # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åˆ¥ã®ç‰¹åŒ–ã‚¯ã‚¨ãƒªç”Ÿæˆ
            species_queries = self._generate_domain_specific_queries(species_name, knowledge_base_type)
            
            for query in species_queries:
                try:
                    search_results = self.search_wikipedia(query, num_results=2)
                    
                    for doc in search_results:
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ç¨®æƒ…å ±ã‚’è¿½åŠ 
                        doc['species_name'] = species_name
                        doc['species_confidence'] = confidence
                        doc['knowledge_domain'] = knowledge_base_type
                        doc['query_type'] = self._extract_query_type(query, knowledge_base_type)
                        dynamic_documents.append(doc)
                        
                except Exception as e:
                    continue
        
        return dynamic_documents

    def _generate_domain_specific_queries(self, species_name: str, knowledge_base_type: str) -> List[str]:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        clean_name = species_name.strip()
        
        if knowledge_base_type == "field_guides":
            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¬ã‚¤ãƒ‰ï¼šè­˜åˆ¥ãƒ»å½¢æ…‹å­¦é‡è¦–
            queries = [
                f"{clean_name} field guide identification",
                f"{clean_name} mushroom identification key features",
                f"{clean_name} morphology cap stem gills pores",
                f"{clean_name} distinguishing characteristics",
                f"{clean_name} lookalike similar species"
            ]
        
        elif knowledge_base_type == "toxicity_reports":
            # æ¯’æ€§ãƒ¬ãƒãƒ¼ãƒˆï¼šå®‰å…¨æ€§ãƒ»æ¯’æ€§é‡è¦–
            queries = [
                f"{clean_name} toxicity poisonous edible",
                f"{clean_name} mushroom safety consumption",
                f"{clean_name} toxic compounds effects",
                f"{clean_name} poisoning symptoms treatment",
                f"{clean_name} edibility safety warnings"
            ]
        
        elif knowledge_base_type == "cooking_recipes":
            # èª¿ç†ãƒ¬ã‚·ãƒ”ï¼šé£Ÿç”¨ãƒ»æ–™ç†é‡è¦–
            queries = [
                f"{clean_name} cooking recipes preparation",
                f"{clean_name} edible mushroom culinary uses",
                f"{clean_name} cooking methods recipes",
                f"{clean_name} food preparation techniques",
                f"{clean_name} mushroom recipes cuisine"
            ]
        
        else:
            # æ±ç”¨æ¤œç´¢ï¼ˆåŸºæœ¬çš„ãªç¨®æƒ…å ±ï¼‰
            clean_name = species_name.strip()
            if any(word in clean_name.lower() for word in ['species', 'mushroom', 'unknown']):
                # ä¸å®Œå…¨ãªç¨®åã®å ´åˆã¯å±åã®ã¿ã‚’ä½¿ç”¨
                genus = clean_name.split()[0] if ' ' in clean_name else clean_name
                queries = [
                    f"{genus} mushroom identification",
                    f"{genus} genus characteristics", 
                    f"{genus} mushroom safety edibility"
                ]
            else:
                # å®Œå…¨ãªç¨®åã®å ´åˆ
                queries = [
                    f"{clean_name} mushroom identification characteristics",
                    f"{clean_name} morphology features",
                    f"{clean_name} toxicity safety edibility",
                    f"{clean_name} habitat distribution ecology"
                ]
        
        return queries

    def _extract_query_type(self, query: str, knowledge_base_type: str) -> str:
        """
        ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
        """
        if "identification" in query or "morphology" in query:
            return "identification"
        elif "toxicity" in query or "poisonous" in query or "safety" in query:
            return "toxicity"
        elif "cooking" in query or "recipe" in query or "culinary" in query:
            return "cooking"
        elif "habitat" in query or "distribution" in query:
            return "ecology"
        else:
            return knowledge_base_type

    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        Retrieve relevant documents for a query
        """
        if self.index is None:
            return []
        
        # Encode query
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        # Search
        scores, indices = self.index.search(query_embedding, top_k)
        
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.documents):
                doc = self.documents[idx].copy()
                doc['relevance_score'] = float(score)
                results.append(doc)
        
        return results

    def generate_context(self, query: str, top_k: int = 3) -> str:
        """
        Generate context string from retrieved documents
        """
        retrieved_docs = self.retrieve(query, top_k)
        
        if not retrieved_docs:
            return "No relevant information found."
        
        context_parts = []
        for i, doc in enumerate(retrieved_docs):
            context_parts.append(f"Source {i+1} ({doc['title']}):\n{doc['content']}")
        
        return "\n\n".join(context_parts)

    def rag_generate(self, query: str, top_k: int = 3) -> Dict:
        """
        Generate response using RAG approach
        """
        # Retrieve relevant context
        context = self.generate_context(query, top_k)
        
        # Create enhanced prompt with context
        enhanced_prompt = f"""Based on the following context information, please answer the question.

Context:
{context}

Question: {query}

Answer:"""
        
        return {
            'context': context,
            'enhanced_prompt': enhanced_prompt,
            'retrieved_docs': self.retrieve(query, top_k)
        }

# %%
# Mobile Mushroom Identification Workflow
@dataclass
class WorkflowResult:
    """3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœ"""
    candidate_species: List[str]
    similarity_scores: List[float]
    toxicity_info: Dict[str, Any]
    cooking_methods: Dict[str, Any]
    safety_warnings: List[str]
    final_answer: str
    recommendation: str

class ImageDatabaseRAG:
    """ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®é¡ä¼¼ç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  (Gemma3nä½¿ç”¨)"""
    
    def __init__(self, image_dataset_path: str, gemma_model, gemma_tokenizer):
        """
        Args:
            image_dataset_path: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
            gemma_model: Gemma3nãƒ¢ãƒ‡ãƒ«
            gemma_tokenizer: Gemma3nãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
        """
        self.dataset_path = image_dataset_path
        self.gemma_model = gemma_model
        self.gemma_tokenizer = gemma_tokenizer
        self.image_embeddings = None
        self.image_metadata = []
        self.index = None

    def build_image_index(self, class_names: List[str], paths: List[str], 
                         classes: List[str]):
        """
        ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ï¼ˆå„ã‚¯ãƒ©ã‚¹5æšã¾ã§å‡ç­‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        
        Args:
            class_names: ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆ
            paths: ç”»åƒãƒ‘ã‚¹ãƒªã‚¹ãƒˆ  
            classes: å„ç”»åƒã®ã‚¯ãƒ©ã‚¹
        """
        # å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå„ã‚¯ãƒ©ã‚¹5æšã¾ã§ï¼‰
        images_per_class = 5
        selected_indices = []
        
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†æ:")
        print(f"   ç·ç”»åƒæ•°: {len(classes)}æš")
        print(f"   ç·ã‚¯ãƒ©ã‚¹æ•°: {len(class_names)}ç¨®é¡")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ã®ç”»åƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†ã—å‡ç­‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        class_indices = {}
        for i, class_name in enumerate(classes):
            if class_name not in class_indices:
                class_indices[class_name] = []
            class_indices[class_name].append(i)
        
        print(f"   å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚¯ãƒ©ã‚¹æ•°: {len(class_indices)}ç¨®é¡")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æƒ…å ±ã‚’è¡¨ç¤º
        sampled_classes = 0
        for class_name in class_indices.keys():
            available = len(class_indices[class_name])
            to_select = min(available, images_per_class)
            if to_select > 0:
                selected_for_class = random.sample(class_indices[class_name], to_select)
                selected_indices.extend(selected_for_class)
                sampled_classes += 1
                if sampled_classes <= 10:  # æœ€åˆã®10ã‚¯ãƒ©ã‚¹ã ã‘è©³ç´°è¡¨ç¤º
                    print(f"   ğŸ“ {class_name}: {available}æšä¸­{to_select}æšé¸æŠ")
        
        print(f"   ğŸ¯ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµæœ: {sampled_classes}ã‚¯ãƒ©ã‚¹ã‹ã‚‰{len(selected_indices)}æšé¸æŠ")
        
        embeddings = []
        metadata = []
        total_images = len(selected_indices)
        
        print(f"ğŸš€ ç”»åƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰é–‹å§‹: {total_images}æšã®ç”»åƒã‚’å‡¦ç†ä¸­...")
        
        # é€²æ—ãƒãƒ¼ç”¨å¤‰æ•°
        successful_extractions = 0
        failed_extractions = 0
        
        for i, idx in enumerate(selected_indices):
            try:
                image_path = paths[idx]
                class_name = classes[idx]
                
                # é€²æ—ãƒãƒ¼è¡¨ç¤º
                progress = (i + 1) / total_images * 100
                bar_length = 30
                filled_length = int(bar_length * (i + 1) // total_images)
                bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
                print(f"\rğŸ“¸ [{i+1:3d}/{total_images}] [{bar}] {progress:5.1f}% | {class_name[:20]:<20}", end='', flush=True)
                
                # Gemma3nã§ç”»åƒã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
                image_embedding = self._extract_image_features(image_path, class_name, verbose=False)
                
                if image_embedding is not None:
                    embeddings.append(image_embedding)
                    metadata.append({
                        'path': image_path,
                        'class': class_name,
                        'class_id': class_names.index(class_name) if class_name in class_names else -1,
                        'index': idx
                    })
                    successful_extractions += 1
                else:
                    failed_extractions += 1
                
            except Exception as e:
                failed_extractions += 1
                continue
        
        # é€²æ—ãƒãƒ¼å®Œäº†
        print(f"\nâœ… ç”»åƒå‡¦ç†å®Œäº†: æˆåŠŸ {successful_extractions}ä»¶, å¤±æ•— {failed_extractions}ä»¶")
        
        if embeddings:
            print(f"ğŸ”§ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ä¸­...")
            self.image_embeddings = np.array(embeddings)
            self.image_metadata = metadata

            # 2æ¬¡å…ƒé…åˆ—ã«å¤‰æ›ï¼ˆFAISSè¦ä»¶ï¼‰
            if self.image_embeddings.ndim != 2:
                # 1æ¬¡å…ƒé…åˆ—ã®å ´åˆã¯ reshapeã—ã¦2æ¬¡å…ƒã«ã™ã‚‹
                if self.image_embeddings.ndim == 1:
                    self.image_embeddings = self.image_embeddings.reshape(1, -1)
                else:
                    # 3æ¬¡å…ƒä»¥ä¸Šã®å ´åˆã¯ flatten
                    self.image_embeddings = self.image_embeddings.reshape(len(embeddings), -1)
            
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
            dimension = self.image_embeddings.shape[1]
            self.index = faiss.IndexFlatIP(dimension)
            self.image_embeddings = np.ascontiguousarray(self.image_embeddings, dtype=np.float32)
            faiss.normalize_L2(self.image_embeddings)
            self.index.add(self.image_embeddings)
            
            print(f"ğŸ‰ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†!")
            print(f"   ğŸ“Š ç™»éŒ²ç”»åƒæ•°: {len(self.image_metadata)}æš")
            print(f"   ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {dimension}æ¬¡å…ƒ")
            
            # ç™»éŒ²ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã®è©³ç´°åˆ†æ
            registered_classes = {}
            for m in self.image_metadata:
                class_name = m['class']
                if class_name not in registered_classes:
                    registered_classes[class_name] = 0
                registered_classes[class_name] += 1
            
            print(f"   ğŸ·ï¸ ç™»éŒ²ã‚¯ãƒ©ã‚¹æ•°: {len(registered_classes)}ç¨®é¡")
            print(f"   ğŸ“‹ ç™»éŒ²ã‚¯ãƒ©ã‚¹è©³ç´°:")
            for i, (class_name, count) in enumerate(registered_classes.items()):
                if i < 20:  # æœ€åˆã®20ã‚¯ãƒ©ã‚¹ã ã‘è¡¨ç¤º
                    print(f"      {i+1:2d}. {class_name}: {count}æš")
                elif i == 20:
                    print(f"      ... ä»–{len(registered_classes)-20}ã‚¯ãƒ©ã‚¹")
        else:
            print(f"âŒ ç”»åƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å¤±æ•—: æœ‰åŠ¹ãªç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ãŒ0å€‹")

    def _extract_image_features(self, image_path: str, class_name: str, verbose: bool = True) -> Optional[np.ndarray]:
        """
        Gemma3nã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            class_name: ç”»åƒã®ã‚¯ãƒ©ã‚¹å
            verbose: è©³ç´°ãƒ­ã‚°ã®è¡¨ç¤º
            
        Returns:
            ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ« (numpyé…åˆ—)
        """
        try:
            if verbose:
                print(f"ğŸ” Gemma3nã§ç”»åƒç‰¹å¾´æŠ½å‡ºä¸­: {image_path} (ã‚¯ãƒ©ã‚¹: {class_name})")
            
            # Gemma3nã«ç”»åƒã®ç‰¹å¾´æŠ½å‡ºã‚’ä¾é ¼
            feature_messages = [{
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": "Extract visual features of this mushroom. Describe in exactly 50 words: cap color, shape, size, stem characteristics, gills/pores, texture, and any distinctive markings."}
                ]
            }]
            
            # Gemma3nã§ç‰¹å¾´ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦å®Ÿéš›ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
            inputs = self.gemma_tokenizer.apply_chat_template(
                feature_messages,
                add_generation_prompt=True,
                tokenize=True,
                return_dict=True,
                return_tensors="pt"
            ).to("cuda")
            
            # ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
            with torch.no_grad():
                outputs = self.gemma_model(**inputs, output_hidden_states=True)
                # æœ€å¾Œã®éš ã‚Œå±¤ã®å¹³å‡ã‚’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦ä½¿ç”¨
                hidden_states = outputs.hidden_states[-1]  # [batch, seq_len, hidden_dim]
                feature_vector = hidden_states.mean(dim=1).squeeze().cpu().numpy()  # [hidden_dim]
            
            if verbose:
                print(f"âœ… ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡ºå®Œäº†: {feature_vector.shape}")
            return feature_vector
            
        except Exception as e:
            if verbose:
                print(f"âš ï¸ Gemma3nç‰¹å¾´æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ“¬ä¼¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨ (ã‚¯ãƒ©ã‚¹: {class_name})")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¯ãƒ©ã‚¹åãƒ™ãƒ¼ã‚¹ã®æ“¬ä¼¼ãƒ™ã‚¯ãƒˆãƒ«
            return self._create_fallback_vector(class_name)

    def _create_fallback_vector(self, class_name: str, dim: int = 768) -> np.ndarray:
        """
        ã‚¯ãƒ©ã‚¹åã‹ã‚‰æ“¬ä¼¼ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        
        Args:
            class_name: ã‚¯ãƒ©ã‚¹å
            dim: ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
            
        Returns:
            æ“¬ä¼¼ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«
        """
        # ã‚¯ãƒ©ã‚¹åã®ãƒãƒƒã‚·ãƒ¥ã‚’ã‚·ãƒ¼ãƒ‰ã«ã—ã¦å®‰å®šã—ãŸæ“¬ä¼¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
        hash_seed = hash(class_name) % (2**31)
        np.random.seed(hash_seed)
        vector = np.random.normal(0, 1, dim)
        np.random.seed()  # ã‚·ãƒ¼ãƒ‰ã‚’ãƒªã‚»ãƒƒãƒˆ
        return vector.astype(np.float32)

    def find_similar_images(self, query_image_path: str, top_k: int = 5) -> List[Dict]:
        """
        ã‚¯ã‚¨ãƒªç”»åƒã«é¡ä¼¼ã—ãŸç”»åƒã‚’æ¤œç´¢
        
        Args:
            query_image_path: ã‚¯ã‚¨ãƒªç”»åƒã®ãƒ‘ã‚¹
            top_k: å–å¾—ã™ã‚‹é¡ä¼¼ç”»åƒæ•°
            
        Returns:
            é¡ä¼¼ç”»åƒã®æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        if self.index is None:
            return []

        try:
            # Gemma3nã§ã‚¯ã‚¨ãƒªç”»åƒã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
            query_vector = self._extract_image_features(query_image_path, "query", verbose=False)
            
            if query_vector is None:
                return []
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ­£è¦åŒ–ã—ã¦FAISSç”¨ã«æº–å‚™
            query_embedding = query_vector.reshape(1, -1).astype(np.float32)
            faiss.normalize_L2(query_embedding)
            
            # é¡ä¼¼ç”»åƒæ¤œç´¢
            scores, indices = self.index.search(query_embedding, top_k)
            
            similar_images = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.image_metadata):
                    metadata = self.image_metadata[idx].copy()
                    metadata['similarity_score'] = float(score)
                    similar_images.append(metadata)
            
            return similar_images
            
        except Exception as e:
            return []

    def get_class_examples(self, class_name: str, max_examples: int = 3) -> List[Dict]:
        """
        æŒ‡å®šã‚¯ãƒ©ã‚¹ã®ä»£è¡¨ç”»åƒã‚’å–å¾—
        
        Args:
            class_name: ã‚¯ãƒ©ã‚¹å
            max_examples: å–å¾—ã™ã‚‹ä¾‹æ•°
            
        Returns:
            ã‚¯ãƒ©ã‚¹ä¾‹ç”»åƒã®ãƒªã‚¹ãƒˆ
        """
        examples = []
        for metadata in self.image_metadata:
            if metadata['class'] == class_name and len(examples) < max_examples:
                examples.append(metadata)
        
        return examples

    def display_image_comparison(self, query_image_path: str, similar_images: List[Dict], top_n: int = 3):
        """
        ãƒ†ã‚¹ãƒˆç”¨: ã‚¯ã‚¨ãƒªç”»åƒã¨é¡ä¼¼ç”»åƒã‚’æ¯”è¼ƒè¡¨ç¤º
        
        Args:
            query_image_path: ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‘ã‚¹
            similar_images: é¡ä¼¼æ¤œç´¢çµæœ
            top_n: è¡¨ç¤ºã™ã‚‹é¡ä¼¼ç”»åƒæ•°
        """
        try:
            from IPython.display import Image, display
            
            print(f"\nğŸ“Š ç”»åƒæ¯”è¼ƒçµæœ:")
            print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆç”»åƒ: {query_image_path}")
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å: {query_image_path.split('/')[-1]}")
            
            # ãƒ†ã‚¹ãƒˆç”»åƒã‚’è¡¨ç¤º
            try:
                display(Image(filename=query_image_path, width=300))
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆç”»åƒè¡¨ç¤ºä¸å¯: {str(e)}")
            
            print(f"\nğŸ” é¡ä¼¼ç”»åƒ Top {min(top_n, len(similar_images))}:")
            for i, img in enumerate(similar_images[:top_n]):
                similarity_percent = img['similarity_score'] * 100
                print(f"\n  {i+1}. {img['class']} (é¡ä¼¼åº¦: {similarity_percent:.1f}%)")
                print(f"     ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {img['path'].split('/')[-1]}")
                print(f"     ğŸ—‚ï¸  ãƒ•ãƒ«ãƒ‘ã‚¹: {img['path']}")
                
                # é¡ä¼¼åº¦ã®è¦–è¦šçš„è¡¨ç¤º
                bar_length = 20
                filled_length = int(bar_length * img['similarity_score'])
                bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
                print(f"     ğŸ“Š [{bar}] {similarity_percent:.1f}%")
                
                # é¡ä¼¼ç”»åƒã‚’è¡¨ç¤º
                try:
                    display(Image(filename=img['path'], width=300))
                except Exception as e:
                    print(f"     âŒ ç”»åƒè¡¨ç¤ºä¸å¯: {str(e)}")
        
        except ImportError:
            # IPython.displayãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿è¡¨ç¤º
            print(f"\nğŸ“Š ç”»åƒæ¯”è¼ƒçµæœ (ãƒ†ã‚­ã‚¹ãƒˆã®ã¿):")
            print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆç”»åƒ: {query_image_path}")
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å: {query_image_path.split('/')[-1]}")
            
            print(f"\nğŸ” é¡ä¼¼ç”»åƒ Top {min(top_n, len(similar_images))}:")
            for i, img in enumerate(similar_images[:top_n]):
                similarity_percent = img['similarity_score'] * 100
                print(f"  {i+1}. {img['class']} (é¡ä¼¼åº¦: {similarity_percent:.1f}%)")
                print(f"     ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {img['path'].split('/')[-1]}")
                print(f"     ğŸ—‚ï¸  ãƒ•ãƒ«ãƒ‘ã‚¹: {img['path']}")
                
                # é¡ä¼¼åº¦ã®è¦–è¦šçš„è¡¨ç¤º
                bar_length = 20
                filled_length = int(bar_length * img['similarity_score'])
                bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
                print(f"     ğŸ“Š [{bar}] {similarity_percent:.1f}%")
                print()


class MobileMushroomWorkflow:
    """ãƒ¢ãƒã‚¤ãƒ«ç«¯æœ«å‘ã‘ã‚­ãƒã‚³è­˜åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆã‚¯ãƒ©ã‚¹ - 3ã‚¹ãƒ†ãƒƒãƒ—ç‰ˆ"""
    
    def __init__(self, model, tokenizer, embedding_model):
        # 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        
        # Step 1: ç”»åƒãƒãƒƒãƒãƒ³ã‚°
        self.image_db = ImageDatabaseRAG("dataset", model, tokenizer)
        
        # Step 2: Wikipediaæ¤œç´¢
        self.wikipedia_rag = WikipediaRAG('all-MiniLM-L6-v2')



    def initialize_image_database(self, image_dataset_path: str, class_names: List[str], 
                                 paths: List[str], classes: List[str]):
        """
        ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ï¼ˆç°¡ç•¥åŒ–ç‰ˆï¼‰
        
        Args:
            image_dataset_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹
            class_names: ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆ
            paths: ç”»åƒãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
            classes: å„ç”»åƒã®ã‚¯ãƒ©ã‚¹
        """
        # 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”¨ã«ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
        self.image_db.build_image_index(class_names, paths, classes)
        print(f"ğŸ“‚ ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±:")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹: {image_dataset_path}")
        print(f"  ã‚¯ãƒ©ã‚¹æ•°: {len(class_names)}")
        print(f"  ç”»åƒæ•°: {len(paths)}")

    def process_image(self, image_path: str, user_question: Optional[str] = None, 
                     verbose: bool = False) -> WorkflowResult:
        """
        3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            user_question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•
            verbose: é€²æ—è¡¨ç¤ºã®æœ‰åŠ¹/ç„¡åŠ¹
            
        Returns:
            WorkflowResult ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        start_time = time.time()
        
        try:
            if verbose:
                print("ğŸš€ 3ã‚¹ãƒ†ãƒƒãƒ—ã‚­ãƒã‚³è­˜åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹...")
            
            # Step 1: ç”»åƒãƒãƒƒãƒãƒ³ã‚°
            if verbose:
                print("ğŸ” Step 1: ç”»åƒãƒãƒƒãƒãƒ³ã‚°ä¸­...")
            similar_images = self.image_db.find_similar_images(image_path, top_k=5)
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨: ç”»åƒæ¯”è¼ƒè¡¨ç¤º
            if verbose and similar_images:
                self.image_db.display_image_comparison(image_path, similar_images, top_n=3)
            
            # ä¸Šä½é¡ä¼¼ç”»åƒã‹ã‚‰å€™è£œç¨®ã‚’æŠ½å‡º
            candidate_species = [img.get('class', 'ä¸æ˜') for img in similar_images[:3]]
            similarity_scores = [img.get('similarity_score', 0.0) for img in similar_images[:3]]
            
            # Step 2: Wikipediaæ¤œç´¢
            if verbose:
                print("ğŸ“š Step 2: Wikipediaæ¤œç´¢ä¸­...")
            
            # å€™è£œç¨®ã«åŸºã¥ã„ã¦Wikipediaæ¤œç´¢
            toxicity_info = {}
            cooking_methods = {}
            safety_warnings = []
            
            for species in candidate_species:
                if species != 'ä¸æ˜':
                    # æ¯’æ€§æƒ…å ±æ¤œç´¢
                    toxicity_query = f"{species} toxicity poisonous edible safety"
                    toxicity_docs = self.wikipedia_rag.search_wikipedia(toxicity_query, num_results=2)
                    toxicity_info[species] = toxicity_docs
                    
                    # èª¿ç†æƒ…å ±æ¤œç´¢
                    cooking_query = f"{species} cooking preparation recipe"
                    cooking_docs = self.wikipedia_rag.search_wikipedia(cooking_query, num_results=2)
                    cooking_methods[species] = cooking_docs
                    
                    # å®‰å…¨è­¦å‘ŠæŠ½å‡º
                    for doc in toxicity_docs:
                        content = doc.get('content', '').lower()
                        if 'toxic' in content or 'poisonous' in content:
                            safety_warnings.append(f"{species}: æ¯’æ€§ã®å¯èƒ½æ€§ã‚ã‚Š")
            
            # Step 3: å›ç­”ç”Ÿæˆ
            if verbose:
                print("ğŸ“ Step 3: å›ç­”ç”Ÿæˆä¸­...")
            
            # æœ€çµ‚å›ç­”ã¨æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
            final_answer = self._generate_answer(candidate_species, toxicity_info, cooking_methods, user_question)
            recommendation = self._generate_recommendation(candidate_species, safety_warnings)
            
            # çµæœä½œæˆ
            total_time = time.time() - start_time
            
            result = WorkflowResult(
                candidate_species=candidate_species,
                similarity_scores=similarity_scores,
                toxicity_info=toxicity_info,
                cooking_methods=cooking_methods,
                safety_warnings=safety_warnings,
                final_answer=final_answer,
                recommendation=recommendation
            )
            
            if verbose:
                print(f"ğŸ‰ 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†! (ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’)")

            return result
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            total_time = time.time() - start_time
            if verbose:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            return WorkflowResult(
                candidate_species=["ã‚¨ãƒ©ãƒ¼"],
                similarity_scores=[0.0],
                toxicity_info={},
                cooking_methods={},
                safety_warnings=["ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã®ãŸã‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„"],
                final_answer=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                recommendation="ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã®ãŸã‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„"
            )

    def _generate_answer(self, candidate_species: List[str], toxicity_info: Dict, 
                        cooking_methods: Dict, user_question: Optional[str]) -> str:
        """æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ"""
        if not candidate_species or candidate_species[0] == 'ä¸æ˜':
            return "ç”»åƒã‹ã‚‰ã‚­ãƒã‚³ã®ç¨®é¡ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚"
        
        answer = f"ä¸Šä½å€™è£œç¨®: {', '.join(candidate_species[:3])}\n\n"
        
        # å®‰å…¨æ€§æƒ…å ±
        has_toxicity = any(
            any('toxic' in doc.get('content', '').lower() or 'poisonous' in doc.get('content', '').lower() 
                for doc in docs) 
            for docs in toxicity_info.values()
        )
        
        if has_toxicity:
            answer += "âš ï¸ æ³¨æ„: æ¯’æ€§ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµ¶å¯¾ã«æ‘‚å–ã—ãªã„ã§ãã ã•ã„ã€‚\n\n"
        else:
            answer += "â„¹ï¸ æ¯’æ€§æƒ…å ±ã¯ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸãŒã€æœ€çµ‚åˆ¤æ–­ã¯å°‚é–€å®¶ã«å§”ã­ã¦ãã ã•ã„ã€‚\n\n"
        
        # èª¿ç†æƒ…å ±
        if cooking_methods:
            answer += "ğŸ³ èª¿ç†æƒ…å ±:\n"
            for species, docs in cooking_methods.items():
                if docs:
                    answer += f"- {species}: èª¿ç†æ³•ãŒç¢ºèªã§ãã¾ã™\n"
        
        answer += "\nâ€¼ï¸ é‡è¦: ã©ã‚“ãªã‚­ãƒã‚³ã§ã‚‚ã€å°‚é–€å®¶ã®ç¢ºèªãªã—ã§ã®æ‘‚å–ã¯å±é™ºã§ã™ã€‚"
        
        return answer
    
    def _generate_recommendation(self, candidate_species: List[str], safety_warnings: List[str]) -> str:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        if safety_warnings:
            return "æ¯’æ€§ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€çµ¶å¯¾ã«æ‘‚å–ã›ãšå°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚"
        elif not candidate_species or candidate_species[0] == 'ä¸æ˜':
            return "è­˜åˆ¥ãŒå›°é›£ãªãŸã‚ã€åˆ¥ã®è§’åº¦ã‹ã‚‰ã®å†™çœŸã‚’æ’®å½±ã—ã€å°‚é–€å®¶ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚"
        else:
            return "æ¯’æ€§æƒ…å ±ã¯ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸãŒã€å®‰å…¨ã®ãŸã‚å¿…ãšå°‚é–€å®¶ã«ç¢ºèªã—ã¦ã‹ã‚‰åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"


#%%
# ãƒ¢ãƒã‚¤ãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆæœŸåŒ–
# ä¸€æ™‚çš„ã«SentenceTransformerã‚’åˆæœŸåŒ–
from sentence_transformers import SentenceTransformer
temp_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

mobile_workflow = MobileMushroomWorkflow(
    model=model,
    tokenizer=tokenizer,
    embedding_model=temp_embedding_model
)

# ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–
mobile_workflow.initialize_image_database(dir0, class_names, paths, classes)

#%%
# 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ - ç°¡æ½”ç‰ˆ
print("ğŸ§ª 3ã‚¹ãƒ†ãƒƒãƒ—ã‚­ãƒã‚³è­˜åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ãƒ†ã‚¹ãƒˆé–‹å§‹")
print("=" * 80)
print("3ï¸âƒ£ æ³¨ï¼šã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯3ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè¡Œã—ã¾ã™")
print("   1.ç”»åƒãƒãƒƒãƒãƒ³ã‚° â†’ 2.Wikipediaæ¤œç´¢ â†’ 3.å›ç­”ç”Ÿæˆ")

# ãƒ†ã‚¹ãƒˆè¨­å®š
test_question = "ã“ã®ã‚­ãƒã‚³ã¯é£Ÿã¹ã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ"
print(f"ğŸ“¸ ãƒ†ã‚¹ãƒˆç”»åƒ: {image_path}")
print(f"â“ ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {test_question}")
print("=" * 80)

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
try:
    print("\nğŸš€ 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–‹å§‹...")
    # è©³ç´°ãªé€²æ—è¡¨ç¤ºã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    result = mobile_workflow.process_image(image_path, test_question, verbose=True)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœ")
    print("=" * 80)
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ”¬ å€™è£œç¨®: {', '.join(result.candidate_species)}")
    print(f"ğŸ“ˆ é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {[f'{s:.3f}' for s in result.similarity_scores]}")
    print(f"âš ï¸ å®‰å…¨è­¦å‘Š: {len(result.safety_warnings)}ä»¶")
    for warning in result.safety_warnings[:3]:
        print(f"   - {warning}")
    print(f"ğŸ’¬ æœ€çµ‚å›ç­”:")
    print(f"   {result.final_answer}")
    print(f"ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print(f"   {result.recommendation}")

except Exception as e:
    print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
    print("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
    import traceback
    traceback.print_exc()

print("\nğŸ 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆå®Œäº†")

#%%
# è¿½åŠ ãƒ†ã‚¹ãƒˆ: 3ã‚¹ãƒ†ãƒƒãƒ—è¤‡æ•°è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³
print("\n" + "=" * 80)
print("ğŸ”¬ 3ã‚¹ãƒ†ãƒƒãƒ—è¿½åŠ ãƒ†ã‚¹ãƒˆ: è¤‡æ•°è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³")
print("=" * 80)
print("ğŸ“Š å„ãƒ†ã‚¹ãƒˆã§3ã‚¹ãƒ†ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªçµæœã‚’å‡ºåŠ›")

test_questions = [
    "ã“ã®ç¨®é¡ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "æ¯’æ€§ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
    "èª¿ç†æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„",
    None  # è³ªå•ãªã—
]

for i, question in enumerate(test_questions, 1):
    print(f"\n--- 3ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ {i}/4 ---")
    print(f"è³ªå•: {question if question else '(è³ªå•ãªã—)'}")
    
    try:
        # ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè¡Œï¼ˆverbose=Falseï¼‰
        start_time = time.time()
        result = mobile_workflow.process_image(image_path, question, verbose=False)
        execution_time = time.time() - start_time
        
        print(f"âœ… å®Ÿè¡ŒæˆåŠŸ (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")
        print(f"   ğŸ”¬ å€™è£œç¨®: {result.candidate_species[:2]}")  # ä¸Šä½2ã¤
        print(f"   ğŸ“ˆ é¡ä¼¼åº¦: {[f'{s:.2f}' for s in result.similarity_scores[:2]]}")
        print(f"   âš ï¸ è­¦å‘Š: {len(result.safety_warnings)}ä»¶")
        print(f"   ğŸ¯ æ¨å¥¨: {result.recommendation[:50]}...")
                
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œå¤±æ•—: {str(e)}")

print("\nğŸ¯ å…¨3ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆå®Œäº†")
print("ğŸ“Š å„ãƒ†ã‚¹ãƒˆã§ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹é€ åŒ–çµæœãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
